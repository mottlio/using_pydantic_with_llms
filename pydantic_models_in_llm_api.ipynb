{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d81e9cc",
   "metadata": {},
   "source": [
    "# Passing the Pydantic model directly in the API call to LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e56a479",
   "metadata": {},
   "source": [
    "Import all required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "86eef1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from pydantic import BaseModel, Field, EmailStr\n",
    "from typing import List, Literal, Optional\n",
    "from openai import OpenAI\n",
    "# instructor is a library for extracting structured data from Large Language Models (LLMs). It is built on top of Pydantic.\n",
    "# instructor extracts the JSON schema from a Pydantic model and passes it in the prompt. It handles retries and parsing of the response.\n",
    "# Instructor takes a 'response_model' parameter in the API call, which is a Pydantic model that defines the structure of the expected response.\n",
    "import instructor\n",
    "import anthropic\n",
    "from dotenv import load_dotenv\n",
    "from datetime import date\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7745d730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the UserInput model for customer support queries\n",
    "class UserInput(BaseModel):\n",
    "    name: str\n",
    "    email: EmailStr\n",
    "    query: str\n",
    "    order_id: Optional[int] = Field(\n",
    "        # Default value is None\n",
    "        None,\n",
    "        description=\"5-digit order number (cannot start with 0)\",\n",
    "        #Greater or equal to 10000 and less than or equal to 99999\n",
    "        ge=10000,\n",
    "        le=99999\n",
    "    )\n",
    "    purchase_date: Optional[date] = None\n",
    "\n",
    "# Define the CustomerQuery model that inherits from UserInput. It adds fields that will be populated by the LLM for priority, category, complaint status, and tags.\n",
    "class CustomerQuery(UserInput):\n",
    "    priority: str = Field(\n",
    "        ..., description=\"Priority level: low, medium, high\"\n",
    "    )\n",
    "    category: Literal[\n",
    "        'refund_request', 'information_request', 'other'\n",
    "    ] = Field(..., description=\"Query category\")\n",
    "    is_complaint: bool = Field(\n",
    "        ..., description=\"Whether this is a complaint\"\n",
    "    )\n",
    "    tags: List[str] = Field(..., description=\"Relevant keyword tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "77ef6723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample user input as a JSON string\n",
    "user_input_json = '''{\n",
    "    \"name\": \"Ula Dobra\",\n",
    "    \"email\": \"ula.dobra@podlasem.com\",\n",
    "    \"query\": \"I would like to know the status of my order.\",\n",
    "    \"order_id\": 87647,\n",
    "    \"purchase_date\": \"2025-01-01\"\n",
    "}'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2068884f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Input:\n",
      "name='Ula Dobra' email='ula.dobra@podlasem.com' query='I would like to know the status of my order.' order_id=87647 purchase_date=datetime.date(2025, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "#Validate the user input against the UserInput model using the model_validate_json method\n",
    "user_input = UserInput.model_validate_json(user_input_json)\n",
    "print(\"User Input:\")\n",
    "print(user_input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc43b47",
   "metadata": {},
   "source": [
    "When using this method, we'll rely on Instructor to pass the JSON schema of the Pydantic model in the API call. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a72058ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#No mention of the desired data structure in the prompt. Instructor will handle that.\n",
    "prompt = (\n",
    "    f\"Analyze the following customer query {user_input} \"\n",
    "    f\"and provide a structured response.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "31f7f99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use Anthropic with Instructor to get structured output (Instructor will work with OpenAI, Grok, Gemini and others as well)\n",
    "anthropic_client = instructor.from_anthropic(\n",
    "    anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
    ")\n",
    "\n",
    "response = anthropic_client.messages.create(\n",
    "    model=\"claude-3-7-sonnet-latest\",  \n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ],\n",
    "    response_model=CustomerQuery  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3f570a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='Ula Dobra' email='ula.dobra@podlasem.com' query='I would like to know the status of my order.' order_id=87647 purchase_date=datetime.date(2025, 1, 1) priority='medium' category='information_request' is_complaint=False tags=['order status', 'inquiry']\n",
      "<class '__main__.CustomerQuery'>\n",
      "{\n",
      "  \"name\": \"Ula Dobra\",\n",
      "  \"email\": \"ula.dobra@podlasem.com\",\n",
      "  \"query\": \"I would like to know the status of my order.\",\n",
      "  \"order_id\": 87647,\n",
      "  \"purchase_date\": \"2025-01-01\",\n",
      "  \"priority\": \"medium\",\n",
      "  \"category\": \"information_request\",\n",
      "  \"is_complaint\": false,\n",
      "  \"tags\": [\n",
      "    \"order status\",\n",
      "    \"inquiry\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response)\n",
    "# Inspect the returned structured data in JSON format\n",
    "print(type(response))\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6596d94",
   "metadata": {},
   "source": [
    "## Testing OpenAI beta API which accepts a 'response_format' argument "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f86ca3",
   "metadata": {},
   "source": [
    "Turns out that OpenAI has a version of their API that also accepts a 'response_format' argument that is a Pydantic model. No need to use Instructor in this case. A lot of the LLM providers are starting to incorporate Pydantic models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b9598f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "{\"name\":\"Ula Dobra\",\"email\":\"ula.dobra@podlasem.com\",\"query\":\"I would like to know the status of my order.\",\"order_id\":87647,\"purchase_date\":\"2025-01-01\",\"priority\":\"medium\",\"category\":\"information_request\",\"is_complaint\":false,\"tags\":[\"order_status\",\"customer_service\"]}\n"
     ]
    }
   ],
   "source": [
    "# Initialize OpenAI client and call passing CustomerQuery in your API call\n",
    "openai_client = OpenAI()\n",
    "response = openai_client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    #They call the below 'constrained generation'\n",
    "    response_format=CustomerQuery\n",
    ")\n",
    "response_content = response.choices[0].message.content\n",
    "print(type(response_content))\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a58e85",
   "metadata": {},
   "source": [
    "## Testing Pydantic AI framework with Google Gemini\n",
    "\n",
    "Link to [Pydantic AI](https://ai.pydantic.dev/#why-use-pydantic-ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7ca50a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try out the Pydantic AI package for defining an agent and getting a structured response\n",
    "from pydantic_ai import Agent\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "agent = Agent(\n",
    "    model=\"google-gla:gemini-2.0-flash\",\n",
    "    output_type=CustomerQuery,\n",
    ")\n",
    "\n",
    "response = agent.run_sync(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3841af34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentRunResult(output=CustomerQuery(name='Ula Dobra', email='ula.dobra@podlasem.com', query='I would like to know the status of my order.', order_id=87647, purchase_date=datetime.date(2025, 1, 1), priority='medium', category='information_request', is_complaint=False, tags=['order status']))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
